\section{Discusión}
Basándonos en nuestro análisis empírico podemos afirmar que los tres estimadores funcionan de manera satisfactoria para distribuciones del tipo uniformes y normales. Esto no debería ser ninguna sorpresa para nosotros, dado que ya fue anticipado por qué debía pasar en la sección 3. Sin embargo, un detalle que no preevimos fue el comportamiento oscilatorio de las comparaciones por mayor del estimador \textbf{Steps} para valores grandes de $S$. Como ya comentamos, este fenómeno se debe a que al agrandarse la cantidad de buckets aumenta significativamente la cantidad de elementos que coinciden con dos o más límites entre buckets (ver sección 2.2, 4.4.1 y 4.4.2).

Analizemos primero las diferencias entre los dos estimadores propuestos por la cátedra.

Mirando el cuadro \ref{tab:hresult} podemos notar que el estimador \textbf{Classic} suele comportarse muy bien en \textbf{todas} las columnas de la base otorgada por la cátedra a la hora de consultar por igualdad. Basándonos en esto, podemos decir que si sabemos de antemano que la mayor parte de las consultas hechas al motor de optimizaciones de la base serán por igualdad, no dudaríamos en elegir \textbf{Classic} sobre \textbf{Steps}.

No ocurre lo mismo cuando la consulta es de selectividad por mayor, como ya fue adelantado por nosotros en diversos puntos. De hecho se ``invierten'' los papeles y quien logra mejores resultados es el estimador \textbf{Steps}. Análogamente entonces, de saber que la mayor parte de consultas será por mayor (o por desigualdades en general) nos inclinaríamos por utilizar \textbf{Steps} (aunque con un valor de $S$ no muy grande).

Igualmente, dado que existen muchos empates en el caso de selectividad por mayor, creemos que la ventaja general la sigue teniendo \textbf{Classic}. Con lo cual para el caso general, si tuviésemos que elegir uno de los dos para tomarlo como estimador sin saber de antemano qué tipo de consultas será la más frecuente, elegiríamos \textbf{Classic}\footnote{Acá estamos asumiendo que el conjunto de distribuciones provisto por la cátedra es representativo de distribuciones existentes en la realidad, lo cual podría no ser cierto.}.

Dicho esto, como ya se mencionó, nuestro estimador es estrictamente mejor que \textbf{Classic} en el caso general y mucho mejor en algunos casos particulares. De hecho logra revertir el resultado adverso en la distribución 0, con lo cual -por igualdad- le gana a \textbf{Steps} en absolutamente todas las distribuciones de la cátedra, sin que este logre hacer lo mismo en las consultas por mayor (venciendo solo en 4 de ellas). Es por esto que nuestro estimador parecería un buen candidato a ganador para una distribución desconocida de antemano. Sin embargo, como presenta problemas similares a \textbf{Classic} a la hora de calcular por mayor en ciertas distribuciones con mucha concentración de datos, no podemos declararlo ideal para todos los casos. Además, su consumo de memoria es el triple, pues agrega al histograma dos estructuras extra también de tamaño proporcional a $S$. Y por último, al igual que comentabamos anteriormente al comparar \textbf{Classic} con \textbf{Steps}, si supiesemos de antemano que las consultas a realizar son por mayor entonces nos inclinaríamos por \textbf{Steps} por sobre el nuestro, ya que mostró una mejor performance en más casos.

Entendemos que difícilmente haya un estimador que funcione de modo correcto en todos los casos. Por lo menos para todos los estimadores que tuvimos la oportunidad de analizar encontramos casos en donde podría funcionar mal (ver sección 3.4 y 4.3).

Como agregado, podemos mencionar que las tres implementaciones tardan tiempo en inicializarse, pero la idea es que cuando alguien realice una consulta a la base demoren muy poco tiempo en devolver una respuesta que se considere correcta. Es necesario que sea rápido dada que se hacen muchas consultas SQL por unidad de tiempo en un servidor. En cambio la creación de cero de un estimador no es tan frecuente, y se pueden aprovechar las noches (o los momentos de menos tráfico) para actualizarlo. 
