\section{Discusión}
Basándonos en nuestro análisis empírico podemos afirmar que los tres estimadores funcionan de manera satisfactoria para distribuciones del tipo uniformes y normales. Esto no debería ser ninguna sorpresa para nosotros, dado que ya fue anticipado por qué debía pasar en la sección 3. Sin embargo, un detalle que no preevimos fue el comportamiento oscilatorio de las comparaciones por mayor del estimador \textbf{Steps} para valores grandes de $S$. Como ya comentamos, este fenómeno se debe a que al agrandarse la cantidad de buckets aumenta significativamente la cantidad de elementos que coinciden con dos o más límites entre buckets (ver sección 2.2, 4.4.1 y 4.4.2).

Analizemos primero las diferencias entre los dos estimadores propuestos por la cátedra.

Mirando el cuadro \ref{tab:hresult} podemos notar que el estimador \textbf{Classic} suele comportarse muy bien en \textbf{todas} las columnas de la base otorgada por la cátedra a la hora de consultar por igualdad. Basándonos en esto, podemos decir que si sabemos de antemano que la mayor parte de las consultas hechas al motor de optimizaciones de la base serán por igualdad, no dudaríamos en elegir \textbf{Classic} sobre \textbf{Steps}.

No ocurre lo mismo cuando la consulta es de selectividad por mayor, como ya fue adelantado por nosotros en diversos puntos. De hecho se ``invierten'' los papeles y quien logra mejores resultados es el estimador \textbf{Steps}. Análogamente entonces, de saber que la mayor parte de consultas será por mayor (o por desigualdades en general) nos inclinaríamos por utilizar \textbf{Steps} (aunque con un valor de $S$ no muy grande).

Igualmente, dado que existen muchos empates en el caso de selectividad por mayor, creemos que la ventaja general la sigue teniendo \textbf{Classic}. Con lo cual para el caso general, si tuviésemos que elegir uno de los dos para tomarlo como estimador sin saber de antemano qué tipo de consultas será la más frecuente, elegiríamos \textbf{Classic}.

Dicho esto, y considerando como ya se mencionó que nuestro estimador es estrictamente mejor que \textbf{Classic} en el caso general y mucho mejor en algunos casos particulares, parecería un buen candidato a ganador para una distribución desconocida de antemano. Sin embargo, presenta problemas similares a \textbf{Classic} a la hora de calcular por mayor en ciertas distribuciones con mucha concentración de datos, con lo cual no podemos declararlo correcto para todos los casos. Además, su consumo de memoria es el triple, pues agrega al histograma dos estructuras extra también de tamaño $S$.

Es por esto que entendemos que difícilmente haya un estimador que funcione de modo correcto en todos los casos. Por lo menos para todos los que pudimos analizar encontramos casos en donde podría funcionar mal (ver sección 3.4).

Como agregado, podemos mencionar que las tres implementaciones tardan tiempo en inicializarse, pero la idea es que cuando alguien realice una consulta a la base demoren muy poco tiempo en devolver una respuesta que se considere correcta. Es necesario que sea rápido dada que se hacen muchas consultas SQL por unidad de tiempo en un servidor. En cambio la creación de cero de un estimador no es tan frecuente, y se pueden aprovechar las noches (o los momentos de menos tráfico) para actualizarlo. 
