\section{Análisis empírico}

\subsection{Performance para distribuciones uniforme}
A continuación mostraremos cómo se comportaron los distintos estimadores en cuanto al error medio obtenido ante la variación del parámetro $S$ (llamado $p$ en el código) de entrada del estimador en una distribución uniforme. Para cada $S$ fueron realizadas $100$ consultas por igualdad y $100$ consultas por mayor.

La distribución uniforme utilizada tiene 10000 elementos de 1 a 10000.

\begin{figure}[h!]  
  \centering
  \includegraphics[width=0.45\textwidth]{../source/datasets/img/uniformeEqual}
  \includegraphics[width=0.45\textwidth]{../source/datasets/img/uniformeGreater}
  \caption{Error medio en función de $S$ para una distribución uniforme, con consultas por igualdad y por mayor respectivamente.}
 \end{figure}
 
 \subsubsection*{Análisis}
Estos datos confirman gran parte del análisis teórico que hicimos en la sección anterior. En primer lugar podemos ver cómo, en el caso de la estimación por igualdad, el parámetro del estimador no modifica de manera alguna la performance. Además, en ese caso la performance de ambos estimadores es muy buena (entre 0.0002 y 0.001), como también habíamos predicho. En el caso de la estimación por mayor confirmamos que en ambos estimadores, a diferencia de la estimación por igualdad, la elección del parámetro cambia drásticamente la performance obtenida, mejorándola al elevar el valor del parámetro.

Un resultado que no estaba contemplado en el análisis teórico es que a partir de cierto valor del parámetro la performance del estimador Distribution Steps oscila erráticamente. Creemos que esto se debe a que llega cierto punto en el que, al tener muchos buckets, comienza a haber valores que aparecen en más de un límite. En esa situación el algoritmo, como ya fue mencionado, caen en el caso en donde intenta minimizar el error en el caso peor caso, obteniendo una performance más pobre en el caso promedio. Intuitivamente podemos decir que pierde precisión al no poder ubicar unívocamente en qué bucket cae el $x_0$ de la consulta.
 
 \subsection{Performance para distribuciones normal}
A continuación mostraremos cómo se comportaron los distintos estimadores en cuanto al error medio obtenido ante la variación del parámetro $S$ de entrada del estimador en una distribución normal. Para cada $S$ fueron realizadas $100$ consultas por igualdad y $100$ consultas por mayor.

La distribución normal utilizada tiene 10000 elementos con $\mu=500$ y $\sigma=100$.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.45\textwidth]{../source/datasets/img/normalEqual}
  \includegraphics[width=0.45\textwidth]{../source/datasets/img/normalGreater}
  \caption{Error medio en función de $S$ para una distribución normal, con consultas por igualdad y por mayor respectivamente.}
 \end{figure}

 \subsubsection*{Análisis}


\subsection{Performance para diferentes distribuciones}
En esta sección calculamos la performance de los estimadores en datasets de diferentes distribuciones provistas por la cátedra y análizamos, en cada caso, mediante un test de hipótesis, si alguno de los estimadores es significativamente mejor o si, en términos estadísticos, no existe una diferencia importante de performance. 
El test utilizado es el \textit{Student’s T-Test Apareado} y para realizarlo necesitamos tener dos conjuntos de datos emparentados que representen la información que queremos comparar. En nuestro caso, para comparar el estimador $A$ con el estimador $B$ en cierto dataset, calculamos por un lado la performance de $A$ para estimar valores individuales del dataset y, por otro lado, la performance de $B$ para estimar esos mismos valores. Esto nos da dos listas de datos que están emparentadas por los valores que se estan estimando. Los valores a estimar cubren todo el rango de valores del dataset en intervalos de 10 unidades. Era necesario calcular la performance individual para diferentes valores del dataset y no simplemente tomar la performance como el promedio de todos esos valores ya que el valor promedio no es suficiente información para llevar adelante un test de hipótesis de estas características.

Presentamos a continuación los gráficos de los datasets utilizados:

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.45\textwidth]{./../source/datasets/img/c0}
  \includegraphics[width=0.45\textwidth]{./../source/datasets/img/c1}
  \caption{Gráficos de los datasets de las columnas c0 y c1}
 \end{figure}
 
 
\begin{figure}[h!]
  \centering
  \includegraphics[width=0.45\textwidth]{./../source/datasets/img/c2}
  \includegraphics[width=0.45\textwidth]{./../source/datasets/img/c3}
  \caption{Gráficos de los datasets de las columnas c2 y c3}
 \end{figure}
 
\begin{figure}[h!]
  \centering
  \includegraphics[width=0.45\textwidth]{./../source/datasets/img/c4}
  \includegraphics[width=0.45\textwidth]{./../source/datasets/img/c5}
  \caption{Gráficos de los datasets de las columnas c4 y c5}
 \end{figure}
 
 
\begin{figure}[h!]
  \centering
  \includegraphics[width=0.45\textwidth]{./../source/datasets/img/c6}
  \includegraphics[width=0.45\textwidth]{./../source/datasets/img/c7}
  \caption{Gráficos de los datasets de las columnas c6 y c7}
 \end{figure}
 
 
\begin{figure}[h!]
  \centering
  \includegraphics[width=0.45\textwidth]{./../source/datasets/img/c8}
  \includegraphics[width=0.45\textwidth]{./../source/datasets/img/c9}
  \caption{Gráficos de los datasets de las columnas c8 y c9}
 \end{figure}
 
 

\newpage

\begin{table}[h!t]
\centering % centering table
\begin{tabular}{c rrrrrrr} % creating eight columns
\hline\hline %inserting double-line
\ &\multicolumn{2}{c}{Propio}& \multicolumn{2}{c}{Classic}& \multicolumn{2}{c}{Steps} \\ [0.5ex] 
\hline % inserts single-line
 & E & G & E & G & E & G &  \\  
\hline
Propio &X  &X  &0-9 &0-9 &0-9 &0-9 \\ % Entering row contents
\hline
Classic &8  &-  &X &X &1-9 &6 \\
\hline
Steps &-  &- &- &0,3-5 &X &X  \\[1ex] % [1ex] adds vertical space
\hline % inserts single-line
\end{tabular}
\caption{Comparación entre estimadores de cual es más significativo, en qué tipo consulta y en qué columnas. } %title of the table
\label{tab:hresult}
\end{table}

\subsubsection*{Análisis}
Como se puede apreciar en \ref{tab:hresult} podemos notar como el estimador creado por nosotros, se queda con todas las ``competencias'' entre los estimadores. Esto es debido a que nuestro estimador es perfecto. Es decir, siempre devolverá la probabilidad exacta del cumplimiento de la consulta (o de una parte de ella). Igualmente vale remarcar que el estimador ``Classic'' logró empatar (no marcar una diferencia significaente según el \textit{Student’s T-Test Apareado}) con el estimador perfecto, lo cual significa que anduvo muy bien en ese caso.
