\section{Análisis teórico}
En esta sección realizamos un análsis teórico sobre la performance de los tres estimadores para tipos de distribuciones variados.

Compararemos primero los dos estimadores sugeridos por la materia y luego haremos un apartado especial para el nuestro.

\subsection{Performance en distribuciones uniformes}
Para responder la pregunta de qué estimador debe exhibir mejor performance en un dataset con distribución uniforme, hace falta primero analizar con detenimiento este tipo de distribución. La distribución uniforme ``reparte'' los elementos en el rango disponible de forma equitativa: todos los enteros tienen la misma probabilidad de ocurrir.

Es decir, la forma de un Histograma Clásico de la distribución tendrá todas las barras del mismo ancho (por invariante de construcción del histograma) y de la misma altura, pues todos los rangos de idéntico ancho tienen aproximadamente la misma cantidad de elementos.

A su vez, la forma de un histograma de Distribution Steps tendrá todas las barras de la misma altura (por invariante de construcción del histograma) y del mismo ancho, pues la cantidad de elementos que resulta ser menor a un cierto porcentaje de los demás está relacionado directamente con ese porcentaje. Dicho en otras palabras, suponiendo un histograma de 10 barras, estas tendrán un ancho aproximado al 10\% del rango de la distribución, pues eso mantiene la condición (propia de Distribution Steps) de que el límite i deja a su izquierda $10i\%$ de los elementos (ver la sección de Estimadores para más información).

Entonces concluimos que dado un mismo parámetro $S$ ambas distribuciones ``dibujarán'' prácticamente el mismo histograma. Esto podría inducir a pensar que la respuesta podría ser similar y que por lo tanto la performance será la misma, pero estaríamos olvidando que ``usan'' esos histogramas de maneras distintas.


\subsubsection{Consultas por igualdad}
Para las consultas por igualdad el Histograma Clásico computa la probabilidad dividiendo la altura de la barra en la que cae $x_0$ por la cantidad de elementos totales ($T$), y dividiendo nuevamente por el ancho de la barra ($~T/S$). De este modo, por ejemplo, si $S$ es 20 y el rango es 1000, una distribución uniforme producirá una respuesta aproximada a $\frac{\frac{50}{1000}}{50} = 0,1\%$ (pues todas las barras tendrán altura aproximada = 50), la cual es una excelente estimación para cualquier $x_0$ en una distribución uniforme (porque coincide con la esperanza de su porcentaje de apariciones). Y podemos ver que esta estimación no depende de $S$, pues $T/S$ aparece tanto como producto como divisor con lo cual se cancelan. Concluimos entonces que la performance del Histograma Clásico no dependerá del parámetro, y que su performance por igualdad será muy buena en una distribución uniforme.

Por otro lado, el método de Distribution Steps (en su versión que minimiza el error en el caso promedio, que es la elegimos implementar) computa en el momento de su construcción el $\delta$ del que ya hablamos y responde basándose en ese valor. En particular en el caso más probable para una distribución uniforme (que $x_0$ coincida con a lo sumo un límite entre buckets, y no con uno extremo\footnote{Este caso es el más probable pues difícilmente en una distribución uniforme coincidan en valor varios límites de buckets: significaría que hay más elementos de ese valor de los que entran en dos buckets, pero para cantidades pequeñas de $S$ en relación al rango de la distribución es muy difícil que ocurra}) el estimador responde exactamente ese $\delta$. Es decir, antes que nada, que su performance difícilmente dependa de $S$ (la cantidad de buckets) salvo que sea tan grande (en relación al rango de la distribución) como para que muchos elementos del mismo valor se extiendan a lo largo de varios buckets. Veamos entonces si ese $\delta$ es una buena estimación en el caso de una distribución uniforme.

$\delta$ es el mínimo entre $0.5/S$ y la densidad. Como ya dijimos, para valores razonables (no muy grandes) de $S$ y distribuciones densas (como es la uniforme) es muy probable que la densidad sea menor a $0.5/S$, por lo cual en general caeremos en el caso $\delta =  densidad$. Como la densidad, informalmente hablando, aproxima el porcentaje medio de valores iguales, en el caso de una distribución uniforme será muy cercana a $1$ sobre la cantidad de elementos distintos, lo cual es exactamente la probabilidad de que un elemento de una distribución uniforme sea igual a un $x_0$ cualquiera. Por esto concluimos que independientemente del parámetro elegido, Distribution Steps tendrá también buena performance por igualdad en una distribución uniforme.

\subsubsection{Consultas por mayor}
Recordemos que para las consultas por mayor el Histograma Clásico computa la selectividad haciendo el promedio entre la probabilidad de que un elemento caiga en buckets mayores al $x_0$ y la de que un elemento caiga en buckets mayores o en el mismo. Como ya comentamos, esto puede traer un error grande para distribuciones en las que los elementos están muy concentrados en pocas regiones. Pero este no es el caso de las distribuciones uniformes, por lo que suponemos que el estimador se comportará correctamente en líneas generales.

Por su lado, el método de Distribution Steps presenta comportamientos matemáticamente más complejos. Como su selectividad por mayor se basa en su selectividad por menor (además de su selectividad por igual, que ya fue analizada), nos resta analizar el error en $Sel(<x_0)$ para obtener una estimación del error total de $Sel(>x_0)$. Nuevamente podemos asumir que $x_0$ coincidirá a lo sumo con un límite no-extremo en la gran mayoría de los casos, con lo cual reducimos los casos interesantes a dos:
\begin{itemize}
 \item Si coincide con un límite no-extremo, $\frac{X}{S} - \frac{\delta}{2}$ será la respuesta. $\frac{X}{S}$ es el porcentaje de elementos a la izquierda de $x_0$, y $\frac{\delta}{2}$ es la mitad de $Sel(=x_0)$ en este mismo caso. Con esa resta entendemos que el algoritmo intenta considerar los casos en que hay más elementos iguales a $x_0$ a la izquierda del límite $X$, y asume que la mitad de ellos están a la izquierda (y la otra mitad a la derecha). La suposición es válida dentro del contexto de una distribución uniforme, con lo cual podemos suponer que la performance será buena.
 \item Si no coincide con ningún límite, $\frac{X+0.5}{S} - \frac{\delta}{2}$ será la respuesta. El razonamiento es similar, solo ``corremos'' el límite $X$ a la derecha $0.5$ asumiendo que $x_0$ cae aproximadamente en la mitad de su bucket. Nuevamente la suposición parece sensata en una distribución uniforme, con lo que asumimos que la performance estará bien.
\end{itemize}

Por último, hace falta aclarar que en ambos estimadores un mayor parámetro $S$ permitirá una precisión mayor, pues aumenta la ``definición'' de los buckets y con eso la veracidad de las suposiciones en las que se basan los estimadores. Como ambos asumen en algún momento que $x_0$ cae en la mitad de su bucket, cuantos menos elementos haya en los mismos más verdadera será la afirmación y por ende mejor será la performance. Concluimos entonces que a un mayor $S$ la performance de ambos estimadores mejorará.

\subsection{Performance en distribuciones normales}
La distribución normal presenta mucha concentración de datos alrededor de una media y va disminuyendo alrededor de ella.

\subsubsection{Consultas por igualdad}
El Histograma Clásico, asumiendo suficiente cantidad de buckets, podrá hacer estimaciones bastante cercanas a la realidad. Mejorará a medida que $S$ aumente, porque podrá evaluar más precisamente las diferentes secciones. En cambio, para valores de $S$ pequeños tendrá mala performance, pues cada bucket abarcará datos con mucha variabilidad dentro suyo.

Distribution Steps estará 

\subsubsection{Consultas por mayor}
El Histograma Clásico tendrá performance pobre en el centro de la distribución, porque es en los buckets más densamente poblados donde presenta mayores problemas para el cálculo de $Sel(>x_0)$. A medida que aumente la cantidad de buckets intuimos que su perfomance mejorará bastante, pues dismiuirá el procentaje de elementos por bucket, reduciendo el error de la estimación.

Distribution Steps también se verá muy beneficiado por un aumento de la definición que le permita analizar con más precisión los sectores de la distribución. En general intuimos que la performance será aceptable, dado que la distribución normal no presenta características que le afecten fuertemente a este estimador.



\subsection{Performance de nuestro estimador propio}
Dado que nuestro estimador obtiene el histograma más detallado posible de la distribución que analiza (pues todo bucket tiene ancho 1) podemos decir que no pierde información. A partir de una instancia de nuestro estimador se puede reconstruir la distribución entera, con lo cual CuentaApariciones\texttrademark es \textbf{perfecto}. Su error siempre será 0 porque tiene en él toda la información necesaria. ¿Dónde está el truco?

Los problemas son tres:
\begin{itemize}
 \item A decir verdad, sí pierde información: se pierde el orden en el que estaban los datos. No se puede reconstruir la columna, solo su multiconjunto de elementos.
 \item Ocupa grandes cantidades de memoria en el caso general. Para darnos una idea, en una distribución de rango un millón con todos los valores poblados, el estimador consume alrededor de 8MB. Puede parecer poco, pero si consideramos que en general las bases de datos usan estimadores para todos los atributos numéricos y en tablas variadas, el número puede salirse de control bastante rápidamente.
 \item Puede ponerse lento para calcular $Sel(>x_0)$ si $x_0$ no aparece en la columna. Tarda tiempo lineal en la cantidad de valores distintos de los elementos (porque hace una búsqueda lineal del máximo elemento menor a $x_0$), lo cual puede ser demasiado tiempo para una gran cantidad de valores distintos.
\end{itemize}

Entonces, concluimos que es un excelente estimador para distribuciones esparsas o de rangos pequeños, pero que puede no funcionar bien para distribuciones densas y muy extensas, y no escala para varias columnas en varias tablas. Lo cual nos lleva a la proxima sección...

\subsection{Distribuciones en las que los estimadores exhiben baja perfomance}
Mencionamos ya un poco este tema en la sección de estimadores. Miremos primero la selectividad por igualdad.
\begin{itemize}
 \item El estimador por Histogramas Clásicos presentará mala performance en una distribución con elementos distribuidos en intervalos y en el medio ``lagunas'' despobladas, por ejemplo la capacidad en GB de un conjunto de discos rígidos. Si la longitud de las lagunas es menor que el ancho de los buckets, siempre que sea consultado por elementos que caigan en las ``lagunas'' responderá una probabilidad grande cuando en realidad la respuesta correcta será 0. Si el ancho de los buckets es menor al de las lagunas, de todos modos la performance será mala en los valores cercanos a los que sí aparecen en la distribución.
 \item El estimador de Distribution Steps presentará mala performance en una distribución donde la simple densidad no sea un buen representante de la probabilidad. Por ejemplo, con elementos distribuidos de formas poco equitativas, donde algunos valores tengan muchos representantes y otros pocos.
\end{itemize}
Respecto a la selectividad por mayor:
\begin{itemize}
 \item Como ya mencionamos, el estimador de Histogramas Clásicos funcionará mal en distribuciones con muchos valores concentrados entre sí. Para valores pequeños de $S$, su estimación para valores que caigan en los buckets más poblados tiene un error muy grande.
 \item Nuevamente en una distribución con mucha variabilidad en sus datos, Distribution Steps se comportará pobremente a la hora de calcular $Sel(>x_0)$.
\end{itemize}
Repetimos que nuestro estimador es perfecto a nivel performance, sus problemas pasan por otro lado.